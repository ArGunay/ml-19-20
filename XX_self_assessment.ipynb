{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XX_self_assessment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreacini/ml-19-20/blob/master/XX_self_assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHIL4EUji5iQ",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning -- Exercises\n",
        "   \n",
        "Prof. Cesare Alippi   \n",
        "Andrea Cini ([`andrea.cini@usi.ch`](mailto:andrea.cini@usi.ch))   \n",
        "Daniele Zambon ([`daniele.zambon@usi.ch`](mailto:daniele.zambon@usi.ch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP6FtEw13LSw",
        "colab_type": "text"
      },
      "source": [
        "## Ex. 0: Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UWrUKK53OzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7CEmzxi3QNS",
        "colab_type": "text"
      },
      "source": [
        "Try to solve all exercises by yourself. You are encouraged to use the documentation, and you can even look up stackoverflow for help; we don't expect you to already know everything, but you should be able to understand the solution you implement. \n",
        "\n",
        "May you find any difficulty in solving the following tasks, try to understand what is problem and try to formulate a question to ask us: we are going to do our best to help you out!\n",
        "\n",
        "Here are the tasks:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zzSBFZUdNIT",
        "colab_type": "text"
      },
      "source": [
        "**T. 1**: Generate a numpy array `A` with 5 rows and 9 columns (a.k.a. a 5x9 matrix) where each component is drawn from a Gaussian distribution with mean 3.5 and standard deviation 0.2. \n",
        "\n",
        "_Hint: look at method np.random.randn ([link](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randn.html))._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qy_K3N83Oc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_HVS3hkd1kG",
        "colab_type": "text"
      },
      "source": [
        "**T. 2:** Reshape matrix `A` to 1-dimensional array `b`. \n",
        "    - Compute and print the mean (average) of the elements of `b` \n",
        "    - Compute and print the variance of the elements of `b` \n",
        "\n",
        "_Hint: if `A` were_\n",
        "```\n",
        "A = [[2, 4, 8 ],\n",
        "    [3, 9, 27]]\n",
        "```\n",
        "_then vector `b` should be_\n",
        "```\n",
        "b = [2, 4, 8, 3, 9, 27]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgdCFEfi3PIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY3gIeQpd13h",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**T. 3:** Compute $C=A A^\\top$, that is the matrix multiplication between $A$ and its transpose \n",
        "\n",
        "_Hint: we saw this in Lab 00._\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FLxKHUfIfBdr",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIZxRKRd2Ta",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**T. 4:** Print the diagonal elements of $C$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VqSwN2zZhu9d",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aJkW-d1d2r-",
        "colab_type": "text"
      },
      "source": [
        "**T. 5:** Compute the trace of $C$, that is the sum of the diagonal elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3Tb-gUE3PZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw8Wd4cThxbV",
        "colab_type": "text"
      },
      "source": [
        "**T. 6:** Find a numpy function to compute the determinant of $C$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fO27uOaobG5",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GSa5LmuuogMy"
      },
      "source": [
        "**T. 7:** Find a function to compute the eigenvalues of `C` and store them in an array `lam`.  \n",
        "_Hint 1: matrix `C` should be symmetric, hence all eigenvalues will be >= 0._ \n",
        "\n",
        "_Hint 2: certain functions to compute the eigenvalues may return complex numbers, in this case the eigenvalues should all have null image part, at least very small_.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3t0WwTC-oblR",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B4RUBj3DohBK"
      },
      "source": [
        "**T. 8:** Print the sum of all eigenvalues `lam`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSLdPE7oobz6",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8AekrJ02ohaO"
      },
      "source": [
        "**T. 9:** Print the product of all eigenvalues `lam`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eJ6vzGS2ocUL",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uIvl3E9noh7M"
      },
      "source": [
        "**T. 10:** Compute the matrix $U$ which has the eigenvectors of $C$ in each column. \n",
        "\n",
        "_Hint: Usually, the function to compute the eigenvalues computes also the eigenvectors._\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8oD1FnuDodrm",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1HvCyH9Mo-RM"
      },
      "source": [
        "\n",
        "**T. 11:** Verify that $U L U^\\top = C$, where $L$ is the matrix with all zero entries, and `lam` as diagonal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EdHF4L3Co-RO",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ESrPJHapNcW",
        "colab_type": "text"
      },
      "source": [
        "## Ex. 1: A regression problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUml7gi3pZTJ",
        "colab_type": "text"
      },
      "source": [
        "Here your task is to to predict the fuel efficiency of a car given its characteristics. \n",
        "\n",
        "We are going to download a dataset from a popular data repository and preprocess it, then you will try to build a model **yourself**.\n",
        "\n",
        "**Dataset variables:**  \n",
        "\n",
        "1. mpg: miles per gallon, continous (our y)\n",
        "2. cylinders: multi-valued discrete\n",
        "3. displacement: continuous\n",
        "4. horsepower: continuous\n",
        "5. weight: continuous\n",
        "6. acceleration: continuous\n",
        "7. model year: multi-valued discrete\n",
        "8. origin: multi-valued discrete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wuf3eYKgF2xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you don't have to understand this code, it is just boilerplate code to download and preprocess the data\n",
        "%tensorflow_version 2.x\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "# some preprocessing steps\n",
        "\n",
        "#here we remove data points with missing values\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.dropna(inplace=True)\n",
        "\n",
        "#here we transform the 'origin' variable into 3 binary features\n",
        "dataset['Origin'] = dataset['Origin'].map(lambda x: {1: 'USA', 2: 'Europe', 3: 'Japan'}.get(x))\n",
        "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
        "\n",
        "#let's see a sample of the dataset\n",
        "dataset.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-oecOU5HeTa",
        "colab_type": "text"
      },
      "source": [
        "We are ready to use the data for learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8lOIVwWG9D9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract features\n",
        "X = dataset[dataset.columns[1:]].values.copy() # now X is a numpy array\n",
        "print('X - Type: {}, Shape: {}'.format(X.dtype, X.shape))\n",
        "\n",
        "# Extact targets\n",
        "y = dataset['MPG'].copy() # now y is a numpy array\n",
        "print('y - Type: {}, Shape: {}'.format(y.dtype, y.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nAB0HlfIDwY",
        "colab_type": "text"
      },
      "source": [
        "Now the data are stored in numpy arrays, go and play with them! You can use the models that we saw on the first lab. \n",
        "\n",
        "Try to check if the training error changes using different models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmRTYR7nheRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idKsELzwjtSo",
        "colab_type": "text"
      },
      "source": [
        "## Demo: Liner regression with gradient descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vW2GQKcE2xp6"
      },
      "source": [
        "Consider the following simple regression problem, where:\n",
        "$$g(x) = 2 + {3 \\over 10}  x$$\n",
        "\n",
        "First we define $g(x)$ in Python, we get some data $y_i = g(x_i) + \\eta$ and we use them to fit a model $f(x; \\boldsymbol \\theta) = \\theta_0 + \\theta_1 x$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ks9V9Wzf7ZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def g(x):\n",
        "    y = 2 + 0.3 * x\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUZW0MHdiJPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(1233)\n",
        "\n",
        "# create n observations\n",
        "n = 20  # number of data points\n",
        "\n",
        "# regressor\n",
        "x = np.linspace(-1, 1, n)  \n",
        "# noise\n",
        "sigma = 0.1  # std of the noise\n",
        "eta = np.random.normal(loc=0, scale=sigma, size=n)\n",
        "# response\n",
        "y = g(x) + eta\n",
        "\n",
        "# plot\n",
        "plt.plot(x, g(x), label='true fun', color ='red');         # real function\n",
        "plt.scatter(x, y, label='noisy data', color='black');      # data affected by noise\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTSR1GbmX-Pl",
        "colab_type": "text"
      },
      "source": [
        "We can estimate $\\hat{\\boldsymbol \\theta}$ using the tools that we saw in the first lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5ngjm0uiJc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = x.reshape(-1, 1)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x, y)\n",
        "\n",
        "theta_hat = np.c_[model.intercept_, model.coef_[0]]\n",
        "print('theta_hat = {}'.format(theta_hat.ravel()))\n",
        "# estimated response\n",
        "y_est = model.predict(x)\n",
        "\n",
        "# plot\n",
        "plt.plot(x, g(x), label='true fun', color='red');              # the real function\n",
        "plt.scatter(x, y, label='noisy data', color='black');          # data affected by noise\n",
        "plt.plot(x, y_est, label='est fun (sklearn)', color='green');  # estimate linear function\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv12xP-dj7n7",
        "colab_type": "text"
      },
      "source": [
        "During the lectures we have seen that, given a model $f(x; {\\boldsymbol \\theta})$ it is possible minimize the training error iteratively using gradient descent:\n",
        "\n",
        "\n",
        "$${\\boldsymbol \\theta}^{i+1} \\gets {\\boldsymbol \\theta}^i - \\varepsilon_L \\frac{\\partial V_n({\\boldsymbol \\theta})}{\\partial {\\boldsymbol \\theta}} \\bigg \\rvert_{{\\boldsymbol \\theta} = {\\boldsymbol \\theta}^i}$$\n",
        "\n",
        "Consider the mean squared error, \n",
        "$$V_n({\\boldsymbol \\theta}) = {1 \\over n}\\sum_{i=1}^n\\left(y_i - f(x_i; \\boldsymbol \\theta)\\right)^2$$\n",
        "then, in our case:\n",
        "$$\\frac{\\partial V_n({\\boldsymbol \\theta})}{\\partial {\\boldsymbol \\theta}} =\n",
        "\\left[ \n",
        "\\begin{array}{c}\n",
        "\\frac{\\partial V_n({\\boldsymbol \\theta})}{\\partial {\\theta_0}} \\\\\n",
        "\\frac{\\partial V_n({\\boldsymbol \\theta})}{\\partial {\\theta_1}}\n",
        "\\end{array}\n",
        "\\right] =\n",
        "\\left[ \n",
        "\\begin{array}{c}\n",
        "-{2 \\over n}\\sum_{i=1}^n\\left(y_i - f(x_i; \\boldsymbol \\theta)\\right) \\\\\n",
        "-{2 \\over n}\\sum_{i=1}^n\\left(y_i - f(x_i; \\boldsymbol \\theta)\\right)x_i\n",
        "\\end{array}\n",
        "\\right] = -{2 \\over n}X^T(Y - X\\boldsymbol \\theta)$$\n",
        "\n",
        "Let's do it in numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZumYWJcoaX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.hstack((np.ones((x.shape[0], 1)), x)) # add a column of ones\n",
        "y = y.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n3qwMDohRx6M",
        "colab": {}
      },
      "source": [
        "def V(X, theta, Y):\n",
        "  return np.mean((Y - np.dot(X, theta))**2)\n",
        "\n",
        "theta = np.array([[-10.], [-5.]]) # initial value theta, it is random you can change it\n",
        "eps = .3  # step size\n",
        "steps = 100 # number of GD steps\n",
        "history = [theta.ravel().copy()]\n",
        "errs = [V(X,theta,y)]\n",
        "\n",
        "for _ in range(steps):  # (Note: underscore `_` is used as name for useless variables) \n",
        "  grad = - 2 * np.dot(X.T, (y - np.dot(X, theta))) / X.shape[0]\n",
        "  theta = theta - eps * grad\n",
        "  # log theta and loss\n",
        "  history.append(theta.ravel().copy())\n",
        "  errs.append(V(X,theta,y))\n",
        "\n",
        "\n",
        "history = np.array(history)\n",
        "print('theta_hat:', theta.ravel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlGLqgJMhHd7",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the iterative procedure converge to the same values of the closed form solution.\n",
        "\n",
        "Let's visualize the descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsPYR5pRTPyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for plotting\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "r = np.abs(history).max()\n",
        "x_range = np.linspace(-r, r, 100)\n",
        "y_range = np.linspace(-r, r, 100)\n",
        "\n",
        "theta_0, theta_1 = np.meshgrid(x_range, y_range)\n",
        "zs = np.array([V(X, t.reshape(-1,1), y) \n",
        "               for t in np.c_[np.ravel(theta_0), np.ravel(theta_1)]])\n",
        "\n",
        "zs = zs.reshape(theta_0.shape)\n",
        "\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "ax1 = fig.add_subplot(122)\n",
        "ax1.set_xlabel(r'$\\theta_0$')\n",
        "ax1.set_ylabel(r'$\\theta_1$')\n",
        "c = ax1.contour(theta_0, theta_1, zs, levels=25,  cmap='viridis')\n",
        "ax1.plot(history[:,0], history[:,1], '-x',color='red')\n",
        "\n",
        "ax2 = fig.add_subplot(121, projection='3d')\n",
        "ax2.plot_trisurf(theta_0.ravel(), theta_1.ravel(), zs.ravel(), cmap='viridis')\n",
        "ax2.set_xlabel(r'$\\theta_0$')\n",
        "ax2.set_ylabel(r'$\\theta_1$')\n",
        "ax2.set_zlabel(r'$V(\\theta)$')\n",
        "ax2.plot(history[:,0], history[:,1], errs, '-x', color='red', alpha=1.)\n",
        "plt.tight_layout();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvAmK69ukSBH",
        "colab_type": "text"
      },
      "source": [
        "You can try to play with the step size. What happens if you increase/decrease it?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSM8y8KFjF12",
        "colab_type": "text"
      },
      "source": [
        "## Ex. 2: Ridge regression with gradient descent\n",
        "\n",
        "Modify the code above to implement Ridge regression.\n",
        "\n",
        "_Hint: You might want to use the Ridge regression implementation on scikit-learn to check the result. To do that, check the scikit-learn documentation and make sure that you are using the same loss function._\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLFcGE0PpFpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}